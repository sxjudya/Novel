#!/usr/bin/env python3
"""
ä¹¦æºæ¸…æ´—è„šæœ¬
- å»é™¤è¡¨æƒ…ç¬¦å·
- å»é™¤æ‹¬å·åŠå†…å®¹
- è§„èŒƒåç§°å’Œåˆ†ç»„
- æ¸…ç†å¤šä½™ç©ºæ ¼
- å¯é€‰ï¼šæŒ‰è¯„åˆ†è‡ªåŠ¨åˆ†ç»„ï¼ˆç²¾é€‰/æ ‡å‡†/å¤‡ç”¨ï¼‰
"""

import json
import re
import time
import argparse
from pathlib import Path

# è¡¨æƒ…ç¬¦å·æ­£åˆ™ï¼ˆè¦†ç›–å¸¸è§ emoji èŒƒå›´ï¼‰
EMOJI_PATTERN = re.compile(
    "["
    "\U0001F300-\U0001F9FF"  # å¸¸è§ emoji
    "\U00002600-\U000027BF"  # æ‚é¡¹ç¬¦å·
    "\U0001FA00-\U0001FAFF"  # æ‰©å±•ç¬¦å·
    "\U00002300-\U000023FF"  # æŠ€æœ¯ç¬¦å·
    "\U00002B50-\U00002B55"  # æ˜Ÿæ˜Ÿç­‰
    "\U0000FE00-\U0000FE0F"  # å˜ä½“é€‰æ‹©å™¨
    "\U0000200D"             # é›¶å®½è¿æ¥ç¬¦
    "]+",
    flags=re.UNICODE
)

# ç‰¹æ®Šç¬¦å·ï¼ˆéœ€è¦ç§»é™¤ï¼‰
SPECIAL_SYMBOLS = re.compile(r'[â˜…â˜†âœ¦âœ§â­ğŸŒŸğŸ’«ğŸ”¥ğŸ’¥âœ¨ğŸ‰ğŸŠğŸ“šğŸ“–ğŸ“•ğŸ“—ğŸ“˜ğŸ“™ğŸ‘ğŸ‘ğŸ‘ğŸ™ğŸ’ªâ¤ï¸ğŸ’•ğŸ’–ğŸ’—ğŸ’™ğŸ’šğŸ’›âœ…âŒâ­•â—â“â‘ â‘¡â‘¢â‘£â‘¤â‘¥â‘¦â‘§â‘¨â‘©â… -â…«ï½~ä¸¨|ï½œğŸ‘ğŸ”°ğŸ¨ğŸ“»ğŸ“¥ğŸ’ ğŸ‰]+')

# æ‹¬å·åŠå†…å®¹ï¼ˆä¸­æ–‡æ‹¬å·ã€è‹±æ–‡æ‹¬å·ã€æ–¹æ‹¬å·ï¼‰
BRACKET_PATTERN = re.compile(r'[ï¼ˆ(ã€\[][^ï¼‰)ã€‘\]]*[ï¼‰)ã€‘\]]')

# åˆ†ç»„åç§°æ˜ å°„ï¼ˆåŸå§‹ -> æ ‡å‡†ï¼‰
GROUP_MAPPING = {
    "ğŸŒŸ æŠ“åŒ…": "æŠ“åŒ…",
    "ğŸ‰ ç²¾é€‰": "ç²¾é€‰",
    "ğŸ”° æ­£ç‰ˆ": "æ­£ç‰ˆ",
    "ğŸ’  ç»¼åˆ": "ç»¼åˆ",
    "ğŸ“¥ ä¸‹è½½": "ä¸‹è½½",
    "ğŸ“š å‡ºç‰ˆ": "å‡ºç‰ˆ",
    "ğŸ¨ æ¼«ç”»": "æ¼«ç”»",
    "ğŸ“» æœ‰å£°": "æœ‰å£°",
    "æŠ“åŒ…": "æŠ“åŒ…",
    "ç²¾é€‰": "ç²¾é€‰",
    "æ­£ç‰ˆ": "æ­£ç‰ˆ",
    "ç»¼åˆ": "ç»¼åˆ",
    "ä¸‹è½½": "ä¸‹è½½",
    "å‡ºç‰ˆ": "å‡ºç‰ˆ",
    "æ¼«ç”»": "æ¼«ç”»",
    "æœ‰å£°": "æœ‰å£°",
}


def calculate_quality_score(source: dict) -> int:
    """è®¡ç®—ä¹¦æºè´¨é‡è¯„åˆ†ï¼ˆæ»¡åˆ†çº¦ 60ï¼‰"""
    score = 0

    # åŸºç¡€çŠ¶æ€ (0-7)
    if source.get('enabled', True):
        score += 5
    if source.get('enabledExplore'):
        score += 2

    # å“åº”æ—¶é—´ (0-15)
    rt = source.get('respondTime', 99999)
    if rt < 1000:
        score += 15
    elif rt < 3000:
        score += 12
    elif rt < 5000:
        score += 8
    elif rt < 10000:
        score += 4

    # è§„åˆ™å®Œæ•´æ€§ (0-20)
    if source.get('searchUrl'):
        score += 4
    if source.get('ruleSearch') or source.get('searchRule'):
        score += 4
    if source.get('ruleToc') or source.get('tocRule'):
        score += 4
    if source.get('ruleContent') or source.get('contentRule'):
        score += 6
    if source.get('exploreUrl'):
        score += 2

    # æ›´æ–°æ—¶é—´ (0-10)
    last = source.get('lastUpdateTime', 0)
    if last:
        days = max(0, (time.time() * 1000 - last) / 86400000)
        if days < 30:
            score += 10
        elif days < 90:
            score += 7
        elif days < 180:
            score += 4
        elif days < 365:
            score += 2

    # æƒé‡ (0-5)
    score += min(source.get('weight', 0) // 100, 5)

    return score


def get_grade_group(score: int) -> str:
    """æ ¹æ®è¯„åˆ†è¿”å›åˆ†ç»„åç§°"""
    if score >= 45:
        return "ç²¾é€‰"
    elif score >= 40:
        return "æ ‡å‡†"
    else:
        return "å¤‡ç”¨"


def strip_decorations(text: str) -> str:
    """ç§»é™¤è£…é¥°æ€§å†…å®¹ï¼ˆè¡¨æƒ…ã€ç‰¹æ®Šç¬¦å·ã€æ‹¬å·åŠå†…å®¹ï¼‰"""
    if not text:
        return ""
    text = EMOJI_PATTERN.sub("", text)
    text = SPECIAL_SYMBOLS.sub("", text)
    text = BRACKET_PATTERN.sub("", text)
    return text


def clean_spaces(text: str) -> str:
    """æ¸…ç†ç©ºæ ¼"""
    if not text:
        return ""
    # å»é™¤é¦–å°¾ç©ºæ ¼
    text = text.strip()
    # å¤šä¸ªç©ºæ ¼åˆå¹¶ä¸ºä¸€ä¸ª
    text = re.sub(r'\s+', ' ', text)
    return text


def normalize_group(group: str) -> str:
    """è§„èŒƒåŒ–åˆ†ç»„åç§°"""
    if not group:
        return ""

    # å…ˆå°è¯•ç›´æ¥æ˜ å°„
    if group in GROUP_MAPPING:
        return GROUP_MAPPING[group]

    # æ¸…æ´—åå†æ˜ å°„
    cleaned = clean_spaces(strip_decorations(group))
    if cleaned in GROUP_MAPPING:
        return GROUP_MAPPING[cleaned]

    return cleaned


def clean_source(source: dict, grade: bool = False) -> dict:
    """æ¸…æ´—å•ä¸ªä¹¦æº"""
    # æ¸…æ´—åç§°
    if "bookSourceName" in source:
        source["bookSourceName"] = clean_spaces(strip_decorations(source["bookSourceName"]))

    # æŒ‰è¯„åˆ†åˆ†ç»„ï¼ˆè¦†ç›–åŸæœ‰åˆ†ç»„ï¼‰
    if grade:
        score = calculate_quality_score(source)
        source["bookSourceGroup"] = get_grade_group(score)
    # ä»…æ¸…æ´—åˆ†ç»„
    elif "bookSourceGroup" in source:
        source["bookSourceGroup"] = normalize_group(source["bookSourceGroup"])

    # æ¸…æ´—å¤‡æ³¨ï¼ˆä¿ç•™å†…å®¹ï¼Œåªå»è¡¨æƒ…ï¼‰
    if "bookSourceComment" in source and source["bookSourceComment"]:
        # å¤‡æ³¨å¯èƒ½åŒ…å«ä½¿ç”¨è¯´æ˜ï¼Œåªå»é™¤å¼€å¤´çš„è¡¨æƒ…
        comment = source["bookSourceComment"]
        # åªæ¸…ç†å¼€å¤´çš„è¡¨æƒ…ç¬¦å·
        comment = re.sub(r'^[\s]*' + EMOJI_PATTERN.pattern, '', comment)
        source["bookSourceComment"] = comment.strip()

    return source


def clean_sources(sources: list, grade: bool = False) -> list:
    """æ‰¹é‡æ¸…æ´—ä¹¦æº"""
    return [clean_source(s, grade) for s in sources]


def main():
    parser = argparse.ArgumentParser(description="ä¹¦æºæ¸…æ´—è„šæœ¬")
    parser.add_argument("--input", "-i", required=True, help="è¾“å…¥æ–‡ä»¶è·¯å¾„")
    parser.add_argument("--output", "-o", required=True, help="è¾“å‡ºæ–‡ä»¶è·¯å¾„")
    parser.add_argument("--grade", "-g", action="store_true", help="æŒ‰è¯„åˆ†è‡ªåŠ¨åˆ†ç»„ï¼ˆç²¾é€‰/æ ‡å‡†/å¤‡ç”¨ï¼‰")
    args = parser.parse_args()

    input_path = Path(args.input)
    output_path = Path(args.output)

    if not input_path.exists():
        print(f"é”™è¯¯ï¼šè¾“å…¥æ–‡ä»¶ä¸å­˜åœ¨ {input_path}")
        return 1

    # è¯»å–ä¹¦æº
    with open(input_path, "r", encoding="utf-8") as f:
        sources = json.load(f)

    print(f"è¯»å–ä¹¦æºï¼š{len(sources)} ä¸ª")
    if args.grade:
        print("å¯ç”¨è¯„åˆ†åˆ†ç»„æ¨¡å¼")

    # æ¸…æ´—
    cleaned = clean_sources(sources, grade=args.grade)

    # è¾“å‡º
    output_path.parent.mkdir(parents=True, exist_ok=True)
    with open(output_path, "w", encoding="utf-8") as f:
        json.dump(cleaned, f, ensure_ascii=False, indent=2)

    print(f"æ¸…æ´—å®Œæˆï¼Œè¾“å‡ºåˆ°ï¼š{output_path}")

    # ç»Ÿè®¡
    groups = {}
    for s in cleaned:
        g = s.get("bookSourceGroup", "æœªåˆ†ç»„")
        groups[g] = groups.get(g, 0) + 1

    print("\nåˆ†ç»„ç»Ÿè®¡ï¼š")
    for g, count in sorted(groups.items(), key=lambda x: -x[1]):
        print(f"  {g or 'æœªåˆ†ç»„'}: {count}")

    return 0


if __name__ == "__main__":
    exit(main())
